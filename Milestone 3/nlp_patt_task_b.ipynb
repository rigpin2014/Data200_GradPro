{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gzip\n",
    " \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling Task B\n",
    "\n",
    "For this analysis we will be creating a linear regression model to predict the hardness score. The hardness score represent the difficulty of the question being asked. Therefore, it is independent of the main dataset (conversation data) or the response embedding data in the auxilliary dataset. To predict the hardness score we will make the assumption that each row of embedding data from the prompt embeddings corresponds to each row of the topic_and_hardness dataset.\n",
    "\n",
    "The problem statement for task B states that we must use linear regression to determine the hardness score. Therefore, any linear model from the sklearn library would meet this criteria. Therefore, we will perform an analysis and return the results of the best performing models. We will then select the top two models for hyperparameter tuning to create our final models, then the best model of the tuned models will be the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary Datasets\n",
    "\n",
    "# Prompt embedding Data -- we will use this data in the \"Embedding Data\" section\n",
    "prompt_embeddings = np.load(\n",
    "    \"../training_data/chatbot-arena-prompts-embeddings.npy\"\n",
    ")\n",
    "\n",
    "# Topic Modeling and Hardness Score Data -- we will use this data in the \"Topic Modeling and Hardness Score Data\" section\n",
    "topic_and_hardness = pd.read_json(\n",
    "    \"../training_data/chatbot-arena-gpt3-scores.jsonl.gz\",\n",
    "    lines=True,\n",
    "    compression=\"gzip\"\n",
    ")\n",
    "\n",
    "# Response embedding Data -- we will use this data in the \"Embedding Data\" section\n",
    "response_embeddings = np.load(\n",
    "    \"../training_data/chatbot-arena-prompts-embeddings.npy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25282, 256)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25282, 256)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25282, 12)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_and_hardness.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>openai_scores_raw_choices_nested</th>\n",
       "      <th>topic_modeling_1</th>\n",
       "      <th>score_reason_1</th>\n",
       "      <th>score_value_1</th>\n",
       "      <th>topic_modeling_2</th>\n",
       "      <th>score_reason_2</th>\n",
       "      <th>score_value_2</th>\n",
       "      <th>topic_modeling_3</th>\n",
       "      <th>score_reason_3</th>\n",
       "      <th>score_value_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58210e39b3fd4441a2bd4a518bb44c2d</td>\n",
       "      <td>What is the difference between OpenCL and CUDA?</td>\n",
       "      <td>[{'finish_reason': 'stop', 'index': 0, 'logpro...</td>\n",
       "      <td>Technical Comparison</td>\n",
       "      <td>This prompt requires the AI to accurately comp...</td>\n",
       "      <td>9</td>\n",
       "      <td>Software Comparison</td>\n",
       "      <td>This prompt assesses the AI's factual accuracy...</td>\n",
       "      <td>8</td>\n",
       "      <td>Comparison, Technology</td>\n",
       "      <td>This prompt requires the AI to demonstrate kno...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        question_id  \\\n",
       "0  58210e39b3fd4441a2bd4a518bb44c2d   \n",
       "\n",
       "                                            prompt  \\\n",
       "0  What is the difference between OpenCL and CUDA?   \n",
       "\n",
       "                    openai_scores_raw_choices_nested      topic_modeling_1  \\\n",
       "0  [{'finish_reason': 'stop', 'index': 0, 'logpro...  Technical Comparison   \n",
       "\n",
       "                                      score_reason_1 score_value_1  \\\n",
       "0  This prompt requires the AI to accurately comp...             9   \n",
       "\n",
       "      topic_modeling_2                                     score_reason_2  \\\n",
       "0  Software Comparison  This prompt assesses the AI's factual accuracy...   \n",
       "\n",
       "  score_value_2        topic_modeling_3  \\\n",
       "0             8  Comparison, Technology   \n",
       "\n",
       "                                      score_reason_3 score_value_3  \n",
       "0  This prompt requires the AI to demonstrate kno...             9  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_and_hardness.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Series.unique of 0             Technical Comparison\n",
       "1               Reasoning, Emotion\n",
       "2                Camera comparison\n",
       "3                    Chatbot Arena\n",
       "4                       Time Query\n",
       "                   ...            \n",
       "25277     Mathematics, Measurement\n",
       "25278        Information Retrieval\n",
       "25279    Training, Hyperparameters\n",
       "25280            Language Modeling\n",
       "25281          Workflow Automation\n",
       "Name: topic_modeling_1, Length: 25282, dtype: object>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_and_hardness[\"topic_modeling_1\"].unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above analysis, majority of the data in the topic_and_hardness dataframe is not useful for analysis. Therefore our method will be to create an ensemble type approach where we train a model to target each of the three score values, then average the result from the three models to obtain the final predicted hardness score. But first we must find out which model performs best on our data.\n",
    "\n",
    "Let us first create our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['question_id', 'prompt', 'openai_scores_raw_choices_nested',\n",
       "       'topic_modeling_1', 'score_reason_1', 'score_value_1',\n",
       "       'topic_modeling_2', 'score_reason_2', 'score_value_2',\n",
       "       'topic_modeling_3', 'score_reason_3', 'score_value_3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_and_hardness.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score_value_1</th>\n",
       "      <th>score_value_2</th>\n",
       "      <th>score_value_3</th>\n",
       "      <th>prompt_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  score_value_1 score_value_2 score_value_3  prompt_length\n",
       "0             9             8             9             47"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the score value columns\n",
    "data = topic_and_hardness[[\"score_value_1\", \"score_value_2\", \"score_value_3\"]].copy()\n",
    "data[\"prompt_length\"] = topic_and_hardness[\"prompt\"].apply(len)\n",
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "score_value_1    26\n",
       "score_value_2    26\n",
       "score_value_3    26\n",
       "prompt_length     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_247</th>\n",
       "      <th>feature_248</th>\n",
       "      <th>feature_249</th>\n",
       "      <th>feature_250</th>\n",
       "      <th>feature_251</th>\n",
       "      <th>feature_252</th>\n",
       "      <th>feature_253</th>\n",
       "      <th>feature_254</th>\n",
       "      <th>feature_255</th>\n",
       "      <th>feature_256</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.123763</td>\n",
       "      <td>-0.117352</td>\n",
       "      <td>0.045677</td>\n",
       "      <td>0.015849</td>\n",
       "      <td>0.085833</td>\n",
       "      <td>-0.027624</td>\n",
       "      <td>0.003787</td>\n",
       "      <td>-0.08236</td>\n",
       "      <td>0.088994</td>\n",
       "      <td>-0.00169</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024708</td>\n",
       "      <td>-0.114236</td>\n",
       "      <td>0.034814</td>\n",
       "      <td>0.006923</td>\n",
       "      <td>0.015938</td>\n",
       "      <td>0.059344</td>\n",
       "      <td>-0.162139</td>\n",
       "      <td>-0.024396</td>\n",
       "      <td>-0.03724</td>\n",
       "      <td>-0.043807</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 256 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
       "0  -0.123763  -0.117352   0.045677   0.015849   0.085833  -0.027624   \n",
       "\n",
       "   feature_7  feature_8  feature_9  feature_10  ...  feature_247  feature_248  \\\n",
       "0   0.003787   -0.08236   0.088994    -0.00169  ...    -0.024708    -0.114236   \n",
       "\n",
       "   feature_249  feature_250  feature_251  feature_252  feature_253  \\\n",
       "0     0.034814     0.006923     0.015938     0.059344    -0.162139   \n",
       "\n",
       "   feature_254  feature_255  feature_256  \n",
       "0    -0.024396     -0.03724    -0.043807  \n",
       "\n",
       "[1 rows x 256 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn the prompt embeddings data into a pandas dataframe\n",
    "num_features = response_embeddings.shape[1]\n",
    "column_names = [f\"feature_{i+1}\" for i in range(num_features)]\n",
    "df_response = pd.DataFrame(response_embeddings, columns = column_names)\n",
    "df_response.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_247</th>\n",
       "      <th>feature_248</th>\n",
       "      <th>feature_249</th>\n",
       "      <th>feature_250</th>\n",
       "      <th>feature_251</th>\n",
       "      <th>feature_252</th>\n",
       "      <th>feature_253</th>\n",
       "      <th>feature_254</th>\n",
       "      <th>feature_255</th>\n",
       "      <th>feature_256</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.123763</td>\n",
       "      <td>-0.117352</td>\n",
       "      <td>0.045677</td>\n",
       "      <td>0.015849</td>\n",
       "      <td>0.085833</td>\n",
       "      <td>-0.027624</td>\n",
       "      <td>0.003787</td>\n",
       "      <td>-0.08236</td>\n",
       "      <td>0.088994</td>\n",
       "      <td>-0.00169</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024708</td>\n",
       "      <td>-0.114236</td>\n",
       "      <td>0.034814</td>\n",
       "      <td>0.006923</td>\n",
       "      <td>0.015938</td>\n",
       "      <td>0.059344</td>\n",
       "      <td>-0.162139</td>\n",
       "      <td>-0.024396</td>\n",
       "      <td>-0.03724</td>\n",
       "      <td>-0.043807</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 256 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
       "0  -0.123763  -0.117352   0.045677   0.015849   0.085833  -0.027624   \n",
       "\n",
       "   feature_7  feature_8  feature_9  feature_10  ...  feature_247  feature_248  \\\n",
       "0   0.003787   -0.08236   0.088994    -0.00169  ...    -0.024708    -0.114236   \n",
       "\n",
       "   feature_249  feature_250  feature_251  feature_252  feature_253  \\\n",
       "0     0.034814     0.006923     0.015938     0.059344    -0.162139   \n",
       "\n",
       "   feature_254  feature_255  feature_256  \n",
       "0    -0.024396     -0.03724    -0.043807  \n",
       "\n",
       "[1 rows x 256 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn the prompt embeddings data into a pandas dataframe\n",
    "num_features = prompt_embeddings.shape[1]\n",
    "column_names = [f\"feature_{i+1}\" for i in range(num_features)]\n",
    "df_prompt = pd.DataFrame(prompt_embeddings, columns = column_names)\n",
    "df_prompt.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_251</th>\n",
       "      <th>feature_252</th>\n",
       "      <th>feature_253</th>\n",
       "      <th>feature_254</th>\n",
       "      <th>feature_255</th>\n",
       "      <th>feature_256</th>\n",
       "      <th>score_value_1</th>\n",
       "      <th>score_value_2</th>\n",
       "      <th>score_value_3</th>\n",
       "      <th>prompt_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.123763</td>\n",
       "      <td>-0.117352</td>\n",
       "      <td>0.045677</td>\n",
       "      <td>0.015849</td>\n",
       "      <td>0.085833</td>\n",
       "      <td>-0.027624</td>\n",
       "      <td>0.003787</td>\n",
       "      <td>-0.082360</td>\n",
       "      <td>0.088994</td>\n",
       "      <td>-0.001690</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015938</td>\n",
       "      <td>0.059344</td>\n",
       "      <td>-0.162139</td>\n",
       "      <td>-0.024396</td>\n",
       "      <td>-0.037240</td>\n",
       "      <td>-0.043807</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.006028</td>\n",
       "      <td>0.028436</td>\n",
       "      <td>-0.091022</td>\n",
       "      <td>0.039573</td>\n",
       "      <td>-0.080445</td>\n",
       "      <td>-0.053600</td>\n",
       "      <td>-0.046251</td>\n",
       "      <td>-0.026352</td>\n",
       "      <td>-0.081835</td>\n",
       "      <td>0.045040</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022912</td>\n",
       "      <td>-0.082866</td>\n",
       "      <td>0.055752</td>\n",
       "      <td>0.085062</td>\n",
       "      <td>-0.053332</td>\n",
       "      <td>0.001854</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.035222</td>\n",
       "      <td>-0.109402</td>\n",
       "      <td>-0.022247</td>\n",
       "      <td>-0.037604</td>\n",
       "      <td>0.037931</td>\n",
       "      <td>-0.049936</td>\n",
       "      <td>-0.011818</td>\n",
       "      <td>0.033610</td>\n",
       "      <td>0.032769</td>\n",
       "      <td>0.022925</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032092</td>\n",
       "      <td>0.055308</td>\n",
       "      <td>-0.035479</td>\n",
       "      <td>-0.141167</td>\n",
       "      <td>0.004774</td>\n",
       "      <td>0.004169</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.050530</td>\n",
       "      <td>-0.004413</td>\n",
       "      <td>0.090092</td>\n",
       "      <td>0.029821</td>\n",
       "      <td>-0.037979</td>\n",
       "      <td>-0.095112</td>\n",
       "      <td>-0.016179</td>\n",
       "      <td>0.006698</td>\n",
       "      <td>-0.063790</td>\n",
       "      <td>0.046847</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013089</td>\n",
       "      <td>0.060516</td>\n",
       "      <td>0.032741</td>\n",
       "      <td>-0.034432</td>\n",
       "      <td>0.045946</td>\n",
       "      <td>-0.063517</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.038406</td>\n",
       "      <td>0.045207</td>\n",
       "      <td>0.061096</td>\n",
       "      <td>0.051551</td>\n",
       "      <td>0.046493</td>\n",
       "      <td>-0.016303</td>\n",
       "      <td>0.058638</td>\n",
       "      <td>0.054352</td>\n",
       "      <td>-0.065154</td>\n",
       "      <td>-0.023475</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070126</td>\n",
       "      <td>-0.039035</td>\n",
       "      <td>-0.083557</td>\n",
       "      <td>-0.045493</td>\n",
       "      <td>0.012152</td>\n",
       "      <td>-0.010252</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 260 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
       "0  -0.123763  -0.117352   0.045677   0.015849   0.085833  -0.027624   \n",
       "1   0.006028   0.028436  -0.091022   0.039573  -0.080445  -0.053600   \n",
       "2  -0.035222  -0.109402  -0.022247  -0.037604   0.037931  -0.049936   \n",
       "3  -0.050530  -0.004413   0.090092   0.029821  -0.037979  -0.095112   \n",
       "4  -0.038406   0.045207   0.061096   0.051551   0.046493  -0.016303   \n",
       "\n",
       "   feature_7  feature_8  feature_9  feature_10  ...  feature_251  feature_252  \\\n",
       "0   0.003787  -0.082360   0.088994   -0.001690  ...     0.015938     0.059344   \n",
       "1  -0.046251  -0.026352  -0.081835    0.045040  ...    -0.022912    -0.082866   \n",
       "2  -0.011818   0.033610   0.032769    0.022925  ...     0.032092     0.055308   \n",
       "3  -0.016179   0.006698  -0.063790    0.046847  ...    -0.013089     0.060516   \n",
       "4   0.058638   0.054352  -0.065154   -0.023475  ...     0.070126    -0.039035   \n",
       "\n",
       "   feature_253  feature_254  feature_255  feature_256  score_value_1  \\\n",
       "0    -0.162139    -0.024396    -0.037240    -0.043807              9   \n",
       "1     0.055752     0.085062    -0.053332     0.001854              9   \n",
       "2    -0.035479    -0.141167     0.004774     0.004169              2   \n",
       "3     0.032741    -0.034432     0.045946    -0.063517              8   \n",
       "4    -0.083557    -0.045493     0.012152    -0.010252              2   \n",
       "\n",
       "   score_value_2  score_value_3  prompt_length  \n",
       "0              8              9             47  \n",
       "1              8              8             49  \n",
       "2              6              2             32  \n",
       "3              8              8             35  \n",
       "4              2              2             17  \n",
       "\n",
       "[5 rows x 260 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the modelling data\n",
    "m_data = pd.concat([df_response, data], axis = 1)\n",
    "#m_data = pd.concat([m_data, data], axis = 1)\n",
    "m_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing values\n",
    "m_data.drop(list(m_data[m_data[\"score_value_1\"].isnull() == True].index), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature_1        0\n",
       "feature_2        0\n",
       "feature_3        0\n",
       "feature_4        0\n",
       "feature_5        0\n",
       "                ..\n",
       "feature_256      0\n",
       "score_value_1    0\n",
       "score_value_2    0\n",
       "score_value_3    0\n",
       "prompt_length    0\n",
       "Length: 260, dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the data\n",
    "for i in range(3):\n",
    "    m_data[f\"score_value_{i+1}\"] = m_data[f\"score_value_{i+1}\"].apply(\n",
    "        # Clean nested list element into an int\n",
    "        lambda x: x[0][0] if isinstance(x, list) and len(x) == 1 and isinstance(x[0], list) and len(x[0]) == 1 else (\n",
    "            # Else clean the list element into an int\n",
    "            x[0] if isinstance(x, list) and len(x) == 1 and isinstance(x[0], (int, float)) \n",
    "            # Else leave it alone\n",
    "            else x\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_251</th>\n",
       "      <th>feature_252</th>\n",
       "      <th>feature_253</th>\n",
       "      <th>feature_254</th>\n",
       "      <th>feature_255</th>\n",
       "      <th>feature_256</th>\n",
       "      <th>score_value_1</th>\n",
       "      <th>score_value_2</th>\n",
       "      <th>score_value_3</th>\n",
       "      <th>prompt_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.123763</td>\n",
       "      <td>-0.117352</td>\n",
       "      <td>0.045677</td>\n",
       "      <td>0.015849</td>\n",
       "      <td>0.085833</td>\n",
       "      <td>-0.027624</td>\n",
       "      <td>0.003787</td>\n",
       "      <td>-0.082360</td>\n",
       "      <td>0.088994</td>\n",
       "      <td>-0.001690</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015938</td>\n",
       "      <td>0.059344</td>\n",
       "      <td>-0.162139</td>\n",
       "      <td>-0.024396</td>\n",
       "      <td>-0.037240</td>\n",
       "      <td>-0.043807</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8</td>\n",
       "      <td>9.0</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.006028</td>\n",
       "      <td>0.028436</td>\n",
       "      <td>-0.091022</td>\n",
       "      <td>0.039573</td>\n",
       "      <td>-0.080445</td>\n",
       "      <td>-0.053600</td>\n",
       "      <td>-0.046251</td>\n",
       "      <td>-0.026352</td>\n",
       "      <td>-0.081835</td>\n",
       "      <td>0.045040</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022912</td>\n",
       "      <td>-0.082866</td>\n",
       "      <td>0.055752</td>\n",
       "      <td>0.085062</td>\n",
       "      <td>-0.053332</td>\n",
       "      <td>0.001854</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8</td>\n",
       "      <td>8.0</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.035222</td>\n",
       "      <td>-0.109402</td>\n",
       "      <td>-0.022247</td>\n",
       "      <td>-0.037604</td>\n",
       "      <td>0.037931</td>\n",
       "      <td>-0.049936</td>\n",
       "      <td>-0.011818</td>\n",
       "      <td>0.033610</td>\n",
       "      <td>0.032769</td>\n",
       "      <td>0.022925</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032092</td>\n",
       "      <td>0.055308</td>\n",
       "      <td>-0.035479</td>\n",
       "      <td>-0.141167</td>\n",
       "      <td>0.004774</td>\n",
       "      <td>0.004169</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.050530</td>\n",
       "      <td>-0.004413</td>\n",
       "      <td>0.090092</td>\n",
       "      <td>0.029821</td>\n",
       "      <td>-0.037979</td>\n",
       "      <td>-0.095112</td>\n",
       "      <td>-0.016179</td>\n",
       "      <td>0.006698</td>\n",
       "      <td>-0.063790</td>\n",
       "      <td>0.046847</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013089</td>\n",
       "      <td>0.060516</td>\n",
       "      <td>0.032741</td>\n",
       "      <td>-0.034432</td>\n",
       "      <td>0.045946</td>\n",
       "      <td>-0.063517</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8</td>\n",
       "      <td>8.0</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.038406</td>\n",
       "      <td>0.045207</td>\n",
       "      <td>0.061096</td>\n",
       "      <td>0.051551</td>\n",
       "      <td>0.046493</td>\n",
       "      <td>-0.016303</td>\n",
       "      <td>0.058638</td>\n",
       "      <td>0.054352</td>\n",
       "      <td>-0.065154</td>\n",
       "      <td>-0.023475</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070126</td>\n",
       "      <td>-0.039035</td>\n",
       "      <td>-0.083557</td>\n",
       "      <td>-0.045493</td>\n",
       "      <td>0.012152</td>\n",
       "      <td>-0.010252</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 260 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
       "0  -0.123763  -0.117352   0.045677   0.015849   0.085833  -0.027624   \n",
       "1   0.006028   0.028436  -0.091022   0.039573  -0.080445  -0.053600   \n",
       "2  -0.035222  -0.109402  -0.022247  -0.037604   0.037931  -0.049936   \n",
       "3  -0.050530  -0.004413   0.090092   0.029821  -0.037979  -0.095112   \n",
       "4  -0.038406   0.045207   0.061096   0.051551   0.046493  -0.016303   \n",
       "\n",
       "   feature_7  feature_8  feature_9  feature_10  ...  feature_251  feature_252  \\\n",
       "0   0.003787  -0.082360   0.088994   -0.001690  ...     0.015938     0.059344   \n",
       "1  -0.046251  -0.026352  -0.081835    0.045040  ...    -0.022912    -0.082866   \n",
       "2  -0.011818   0.033610   0.032769    0.022925  ...     0.032092     0.055308   \n",
       "3  -0.016179   0.006698  -0.063790    0.046847  ...    -0.013089     0.060516   \n",
       "4   0.058638   0.054352  -0.065154   -0.023475  ...     0.070126    -0.039035   \n",
       "\n",
       "   feature_253  feature_254  feature_255  feature_256  score_value_1  \\\n",
       "0    -0.162139    -0.024396    -0.037240    -0.043807            9.0   \n",
       "1     0.055752     0.085062    -0.053332     0.001854            9.0   \n",
       "2    -0.035479    -0.141167     0.004774     0.004169            2.0   \n",
       "3     0.032741    -0.034432     0.045946    -0.063517            8.0   \n",
       "4    -0.083557    -0.045493     0.012152    -0.010252            2.0   \n",
       "\n",
       "   score_value_2  score_value_3  prompt_length  \n",
       "0              8            9.0             47  \n",
       "1              8            8.0             49  \n",
       "2              6            2.0             32  \n",
       "3              8            8.0             35  \n",
       "4              2            2.0             17  \n",
       "\n",
       "[5 rows x 260 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Processing Libraries\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, KFold, cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Model Building Libraries\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.linear_model import (\n",
    "    LinearRegression,\n",
    "    Ridge, \n",
    "    Lasso,\n",
    "    ElasticNet,\n",
    "    SGDRegressor,\n",
    "    BayesianRidge,\n",
    "    ARDRegression\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "# Split the data into X and y\n",
    "X = m_data.drop(columns = [\"score_value_1\", \"score_value_2\", \"score_value_3\"])\n",
    "y_1 = m_data[\"score_value_1\"]\n",
    "y_2 = m_data[\"score_value_2\"]\n",
    "y_3 = m_data[\"score_value_3\"]\n",
    "\n",
    "X_train, X_test, y_train_1, y_test_1 = train_test_split(X, y_1, test_size = 0.3, random_state = 42)\n",
    "_, _, y_train_2, y_test_2 = train_test_split(X, y_2, test_size = 0.3, random_state = 42)\n",
    "_, _, y_train_3, y_test_3 = train_test_split(X, y_3, test_size = 0.3, random_state = 42)\n",
    "\n",
    "# Scale the data.\n",
    "scaler = StandardScaler()\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_test_s = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8684     8.0\n",
       "3273     7.0\n",
       "12870    7.0\n",
       "25162    9.0\n",
       "17897    8.0\n",
       "        ... \n",
       "21589    8.0\n",
       "5392     8.0\n",
       "861      8.0\n",
       "15808    8.0\n",
       "23668    7.0\n",
       "Name: score_value_1, Length: 17679, dtype: float64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-Validation MSE on Training Data:\n",
      "LinearRegression: 2.6539774077052627\n",
      "Ridge: 2.653964388762386\n",
      "Lasso: 3.614491152408501\n",
      "ElasticNet: 3.614491152408501\n",
      "SGDRegressor: 2.7568733667495446\n",
      "BayesianRidge: 2.6481119432862767\n",
      "ARDRegression: 2.6570359163228963\n",
      "\n",
      "MSE on Testing Data:\n",
      "LinearRegression: 2.7925353042101095\n",
      "Ridge: 2.7925353042101095\n",
      "Lasso: 3.7500910650653294\n",
      "ElasticNet: 3.7500910650653294\n",
      "SGDRegressor: 2.842766266332321\n",
      "BayesianRidge: 2.7925353042101095\n",
      "ARDRegression: 2.807184901676125\n"
     ]
    }
   ],
   "source": [
    "# Create an empty list to store all of the models for testing\n",
    "models = []\n",
    "\n",
    "# Append models into the list\\\n",
    "models.append((\"LinearRegression\", LinearRegression()))\n",
    "models.append((\"Ridge\", Ridge()))\n",
    "models.append((\"Lasso\", Lasso()))\n",
    "models.append((\"ElasticNet\",ElasticNet()))\n",
    "models.append((\"SGDRegressor\", SGDRegressor()))\n",
    "models.append((\"BayesianRidge\", BayesianRidge()))\n",
    "models.append((\"ARDRegression\", ARDRegression()))\n",
    "\n",
    "# Create lists to store the output of the training loop\n",
    "model_names = []\n",
    "train_MSE = []\n",
    "test_MSE = []\n",
    "\n",
    "# Loop through the models to obtain mean cross-validated MSE scores\n",
    "for name, model in models:\n",
    "\n",
    "    # Add the model name to the list for this iteration\n",
    "    model_names.append(name)\n",
    "\n",
    "    # Set training parameters\n",
    "    scoring = \"neg_mean_squared_error\"\n",
    "    kfold = KFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "\n",
    "    # Get the mean cross-validated MSE score on the training data\n",
    "    train_cv_result = cross_val_score(estimator = model, X = X_train_s, y = y_train_1, cv = kfold, scoring = scoring)\n",
    "    avg_train_MSE = -train_cv_result.mean()\n",
    "    train_MSE.append(avg_train_MSE)\n",
    "    \n",
    "\n",
    "    # Get the MSE score on the test data\n",
    "    model.fit(X_train_s, y_train_1)\n",
    "    y_pred = model.predict(X_test_s)\n",
    "    y_pred_int = np.round(y_pred).astype(int) # Round predictions to nearest integer\n",
    "    comp_MSE = mean_squared_error(y_test_1, y_pred_int)\n",
    "    test_MSE.append(comp_MSE)\n",
    "\n",
    "# Print Results\n",
    "print(\"\\n\" \"Cross-Validation MSE on Training Data:\")\n",
    "for i in range(len(model_names)):\n",
    "    print(\"{}: {}\".format(model_names[i], train_MSE[i]))\n",
    "\n",
    "print(\"\\n\" \"MSE on Testing Data:\")\n",
    "for i in range(len(model_names)):\n",
    "    print(\"{}: {}\".format(model_names[i], test_MSE[i]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above analysis you can see that the models perform similarly on the testing and training data, but there are some slight differences. \n",
    "\n",
    "The Lasso and ElasticNet models have the highest MSE at ~1.93 and ~1.59. The SGDRegressor model is clearly the fifth place candidate based on its MSE of ~0.8 on the testing data.\n",
    "\n",
    "The remaining models have similar MSE scores on the test data. By obersving the Ridge and Linear Regression models and applying some critical thinking, we can conclude that when using mean_squared_error as the loss metric for the Linear Regression model it effectively becomes a Ridge model. Therefore the top three candidates are: Ridge, ARDRegression, and BayesianRidge.\n",
    "\n",
    "We will choose the Ridge model and the ARDRegression model as our top two models to perform hyperparameter tuning on.\n",
    "\n",
    "Note: The Ridge model only has one parameter for hyperparameter tuning, alpha. The ARDRegression model has four parameters for tuning: alpha_1, alpha_2, lambda_1, lambda_2.\n",
    "\n",
    "## Hyperparameter Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best alpha is 1e-10\n",
      "The cross-validated MSE for the best Ridge model is 2.650754617963383\n",
      "The MSE of the best Ridge model versus the test data is 2.7925353042101095\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning for Ridge model\n",
    "\n",
    "# Set up the parameter grid\n",
    "param_grid = {\n",
    "    \"alpha\" : [1E-10, 1E-9, 1E-8, 1E-7, 1E-6, 1E-5, 1E-4, 1E-3]}\n",
    "scoring = 'neg_mean_squared_error'\n",
    "\n",
    "# Perform GridSearchCV across the parameter grid\n",
    "grid_search = GridSearchCV(estimator = Ridge(), \n",
    "                           param_grid = param_grid, \n",
    "                           cv = 5,\n",
    "                           scoring = 'neg_mean_squared_error',\n",
    "                           return_train_score = True # Return the MSE for each alpha in .cv_results_\n",
    "                           )\n",
    "grid_search.fit(X_train_s, y_train_1)\n",
    "\n",
    "# Create empty variables to store the best model\n",
    "best_ridge_model = []\n",
    "best_alpha = []\n",
    "best_ridge_train_MSE = None\n",
    "best_ridge_test_MSE = float(\"inf\")\n",
    "\n",
    "# Loop through each alpha in the parameter grid\n",
    "for i, param in enumerate(grid_search.cv_results_[\"params\"]):\n",
    "\n",
    "    # Obtain the train_MSE for the iteration\n",
    "    train_MSE = -grid_search.cv_results_[\"mean_test_score\"][i]\n",
    "\n",
    "    # Train the Ridge model on the alpha for this iteration\n",
    "    model = Ridge(alpha = param[\"alpha\"])\n",
    "    model.fit(X_train_s, y_train_1)\n",
    "    y_pred = model.predict(X_test_s)\n",
    "    y_pred_int = np.round(y_pred).astype(int)\n",
    "\n",
    "    # Obtain the test_MSE for the iteration\n",
    "    test_MSE = mean_squared_error(y_test_1, y_pred_int)\n",
    "\n",
    "    if test_MSE < best_ridge_test_MSE:\n",
    "        best_ridge_model = model\n",
    "        best_alpha = param[\"alpha\"]\n",
    "        best_ridge_train_MSE = train_MSE\n",
    "        best_ridge_test_MSE = test_MSE\n",
    "\n",
    "# Print the results\n",
    "print(f\"The best alpha is {best_alpha}\")\n",
    "print(f\"The cross-validated MSE for the best Ridge model is {best_ridge_train_MSE}\")\n",
    "print(f\"The MSE of the best Ridge model versus the test data is {best_ridge_test_MSE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cross-validated MSE for the best ARDRegression model is 2.6478653160508805\n",
      "The MSE of the best ARDRegression model versus the test data is 2.790687607232414\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning for BayesianRidge model\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Set up the parameter grid\n",
    "param_grid = {\n",
    "    \"alpha_1\" : [0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1, 1],\n",
    "    \"alpha_2\" : [0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1, 1],\n",
    "    \"lambda_1\" : [0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1, 1],\n",
    "    \"lambda_2\" : [0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1, 1],\n",
    "    \n",
    "}\n",
    "scoring = 'neg_mean_squared_error'\n",
    "\n",
    "# Perform GridSearchCV across the parameter grid\n",
    "rand_search = RandomizedSearchCV(estimator = ARDRegression(), \n",
    "                           param_distributions = param_grid, \n",
    "                           cv = 5,\n",
    "                           scoring = 'neg_mean_squared_error',\n",
    "                           return_train_score = True, # Return the MSE for each alpha in .cv_results_\n",
    "                           n_iter = 100,\n",
    "                           random_state = 42, \n",
    "                           n_jobs = -1\n",
    "                           )\n",
    "rand_search.fit(X_train_s, y_train_1)\n",
    "\n",
    "# Create empty variables to store the best model\n",
    "best_params = []\n",
    "best_ARD_train_MSE = None\n",
    "best_ARD_test_MSE = float(\"inf\")\n",
    "\n",
    "# Loop through each alpha in the parameter grid\n",
    "for i, param in enumerate(rand_search.cv_results_[\"params\"]):\n",
    "\n",
    "    # Obtain the train_MSE for the iteration\n",
    "    train_MSE = -rand_search.cv_results_[\"mean_test_score\"][i]\n",
    "\n",
    "    # Train the Ridge model on the alpha for this iteration\n",
    "    model = ARDRegression(**param)  # Use ** for every combination of possible parameters\n",
    "    model.fit(X_train_s, y_train_1)\n",
    "    y_pred = model.predict(X_test_s)\n",
    "    y_pred_int = np.round(y_pred).astype(int)\n",
    "\n",
    "    # Obtain the test_MSE for the iteration\n",
    "    test_MSE = mean_squared_error(y_test_1, y_pred_int)\n",
    "\n",
    "    if test_MSE < best_ARD_test_MSE:\n",
    "        best_ARD_model = model\n",
    "        best_params = param\n",
    "        best_ARD_train_MSE = train_MSE\n",
    "        best_ARD_test_MSE = test_MSE\n",
    "\n",
    "# Print the results\n",
    "print(f\"The cross-validated MSE for the best ARDRegression model is {best_ARD_train_MSE}\")\n",
    "print(f\"The MSE of the best ARDRegression model versus the test data is {best_ARD_test_MSE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lambda_2': 0.0001, 'lambda_1': 1, 'alpha_2': 1e-06, 'alpha_1': 1e-05}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtain the best parameters for the final ARDRegression model\n",
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have determined our best model, let us employ our ensemble method to obtain the most accurate prediction given the probabalistic responses of GPT3.5. To do this we are going to train three models on each of the score values generated by GPT3.5 and then average the results of the models to obtain our final prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17679, 259)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE of the ARDRegression model predicting 'score_value_1' is 0.7035689059689595.\n",
      "The MSE of the ARDRegression model predicting 'score_value_2' is 0.7247891585771813.\n",
      "The MSE of the ARDRegression model predicting 'score_value_3' is 0.7101071992500068.\n",
      "The MSE of the ARDRegression Ensemble agains the test data for 'score_value_1' is: 0.7762755708063878.\n",
      "The MSE of the ARDRegression Ensemble agains the test data for 'score_value_2' is: 0.8230170252078659.\n",
      "The MSE of the ARDRegression Ensemble agains the test data for 'score_value_3' is: 0.821471558664379.\n"
     ]
    }
   ],
   "source": [
    "# Split the data for y2 and y3 on indices to align with y\n",
    "y2 = m_data[\"score_value_2\"]\n",
    "y3 = m_data[\"score_value_3\"]\n",
    "\n",
    "_, _, y2_train, y2_test = train_test_split(X, y2, test_size = 0.3, random_state = 42)\n",
    "_, _, y3_train, y3_test = train_test_split(X, y3, test_size = 0.3, random_state = 42)\n",
    "\n",
    "# Initialize the models\n",
    "model1 = ARDRegression(alpha_1 = 1E-5, alpha_2 = 1E-6, lambda_1 = 1, lambda_2 = 0.0001)\n",
    "model2 = ARDRegression(alpha_1 = 1E-5, alpha_2 = 1E-6, lambda_1 = 1, lambda_2 = 0.0001)\n",
    "model3 = ARDRegression(alpha_1 = 1E-5, alpha_2 = 1E-6, lambda_1 = 1, lambda_2 = 0.0001)\n",
    "\n",
    "# Set training parameters\n",
    "scoring = \"neg_mean_squared_error\"\n",
    "kfold1 = KFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "kfold2 = KFold(n_splits = 5, shuffle = True, random_state = 16)\n",
    "kfold3 = KFold(n_splits = 5, shuffle = True, random_state = 6)\n",
    "\n",
    "# Get the mean cross-validated MSE score on the training data\n",
    "train_cv_result_1 = cross_val_score(estimator = model1, X = X_train_s, y = y_train, cv = kfold1, scoring = scoring)\n",
    "train_cv_result_2 = cross_val_score(estimator = model2, X = X_train_s, y = y2_train, cv = kfold2, scoring = scoring)\n",
    "train_cv_result_3 = cross_val_score(estimator = model3, X = X_train_s, y = y3_train, cv = kfold3, scoring = scoring)\n",
    "\n",
    "avg_train_MSE_1 = -train_cv_result_1.mean()\n",
    "avg_train_MSE_2 = -train_cv_result_2.mean()\n",
    "avg_train_MSE_3 = -train_cv_result_3.mean()    \n",
    "\n",
    "# Fit the models and obtain predictions\n",
    "model1.fit(X_train_s, y_train)\n",
    "y1_pred = model.predict(X_test_s)\n",
    "y1_pred_int = np.round(y1_pred).astype(int) # Round predictions to nearest integer\n",
    "\n",
    "model2.fit(X_train_s, y2_train)\n",
    "y2_pred = model.predict(X_test_s)\n",
    "y2_pred_int = np.round(y2_pred).astype(int) # Round predictions to nearest integer\n",
    "\n",
    "model3.fit(X_train_s, y3_train)\n",
    "y3_pred = model.predict(X_test_s)\n",
    "y3_pred_int = np.round(y3_pred).astype(int) # Round predictions to nearest integer\n",
    "\n",
    "# Print the MSE of the training data\n",
    "print(f\"The MSE of the ARDRegression model predicting 'score_value_1' is {avg_train_MSE_1}.\")\n",
    "print(f\"The MSE of the ARDRegression model predicting 'score_value_2' is {avg_train_MSE_2}.\")\n",
    "print(f\"The MSE of the ARDRegression model predicting 'score_value_3' is {avg_train_MSE_3}.\")\n",
    "\n",
    "# Add results to a dataframe and obtain the average prediction\n",
    "df_final = pd.DataFrame()\n",
    "df_final[\"model_1_pred\"] = y1_pred_int\n",
    "df_final[\"model_2_pred\"] = y2_pred_int\n",
    "df_final[\"model_3_pred\"] = y3_pred_int\n",
    "df_final[\"avg_pred\"] = np.round(df_final[[\"model_1_pred\", \"model_2_pred\", \"model_3_pred\"]].mean(axis = 1)).astype(int)\n",
    "\n",
    "# Obtain the MSE on the test data using the average prediction\n",
    "test_MSE_1  = mean_squared_error(y_test, df_final[\"avg_pred\"])\n",
    "test_MSE_2  = mean_squared_error(y2_test, df_final[\"avg_pred\"])\n",
    "test_MSE_3  = mean_squared_error(y3_test, df_final[\"avg_pred\"])\n",
    "print(f\"The MSE of the ARDRegression Ensemble agains the test data for 'score_value_1' is: {test_MSE_1}.\")\n",
    "print(f\"The MSE of the ARDRegression Ensemble agains the test data for 'score_value_2' is: {test_MSE_2}.\")\n",
    "print(f\"The MSE of the ARDRegression Ensemble agains the test data for 'score_value_3' is: {test_MSE_3}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Against the Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary Datasets\n",
    "\n",
    "# Embedding Data -- we will use this data in the \"Embedding Data\" section\n",
    "test_prompt_embeddings = np.load(\n",
    "    \"../testing_data/arena-test-set-prompts-embeddings.npy\"\n",
    ")\n",
    "\n",
    "# Topic Modeling and Hardness Score Data -- we will use this data in the \"Topic Modeling and Hardness Score Data\" section\n",
    "topic_and_hardness = pd.read_json(\n",
    "    \"../testing_data/arena-test-set-topic-modeling.jsonl.gz\",\n",
    "    lines=True,\n",
    "    compression=\"gzip\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.05513094, -0.11570924,  0.05522487, ..., -0.01544981,\n",
       "        -0.03390506, -0.05747894],\n",
       "       [-0.02218126, -0.03471164, -0.05304605, ...,  0.01184425,\n",
       "        -0.05673543,  0.10960151],\n",
       "       [ 0.0456381 , -0.08502936,  0.00432697, ..., -0.06711485,\n",
       "         0.07976342, -0.02999518],\n",
       "       ...,\n",
       "       [-0.01514673, -0.06583532,  0.09111056, ..., -0.02442352,\n",
       "        -0.07683857, -0.05174748],\n",
       "       [ 0.02692666, -0.04334887, -0.03203418, ..., -0.04427489,\n",
       "         0.11957113, -0.10678061],\n",
       "       [ 0.1114219 , -0.00910184,  0.03681982, ...,  0.01050424,\n",
       "        -0.02826794,  0.09706794]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prompt_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>topic_modeling_1</th>\n",
       "      <th>topic_modeling_2</th>\n",
       "      <th>topic_modeling_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4f332ebd8cdc4ff2be74aa8828ff20d5</td>\n",
       "      <td>what do you think about the future of iran?</td>\n",
       "      <td>Future Prediction</td>\n",
       "      <td>Future Prediction</td>\n",
       "      <td>Future Prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f2be6f13e5ed40e5b81443223996494c</td>\n",
       "      <td>Salut ! Tu es un méchant chatbot !</td>\n",
       "      <td>Role-playing, Evaluation</td>\n",
       "      <td>Role-play, Evaluation</td>\n",
       "      <td>Creativity, Factual Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5fafefb8a0c54243afb52d2892946cea</td>\n",
       "      <td>⚔️ Chatbot Arena ⚔️\\nRules:\\n    Chat with two...</td>\n",
       "      <td>Chatbot Evaluation</td>\n",
       "      <td>Chatbot Evaluation</td>\n",
       "      <td>Chatbot Evaluation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7834f572267f40709ecebb273a2b346b</td>\n",
       "      <td>Guess the word that i have in my mind</td>\n",
       "      <td>Guessing Game</td>\n",
       "      <td>Word Guessing</td>\n",
       "      <td>Word Guessing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1ccc7e58290245c4bd5457fce45f8640</td>\n",
       "      <td>You are a peasant living in the village. But s...</td>\n",
       "      <td>Problem-Solving, Creativity</td>\n",
       "      <td>Problem Solving</td>\n",
       "      <td>Problem-solving, Creativity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        question_id  \\\n",
       "0  4f332ebd8cdc4ff2be74aa8828ff20d5   \n",
       "1  f2be6f13e5ed40e5b81443223996494c   \n",
       "2  5fafefb8a0c54243afb52d2892946cea   \n",
       "3  7834f572267f40709ecebb273a2b346b   \n",
       "4  1ccc7e58290245c4bd5457fce45f8640   \n",
       "\n",
       "                                              prompt  \\\n",
       "0        what do you think about the future of iran?   \n",
       "1                 Salut ! Tu es un méchant chatbot !   \n",
       "2  ⚔️ Chatbot Arena ⚔️\\nRules:\\n    Chat with two...   \n",
       "3              Guess the word that i have in my mind   \n",
       "4  You are a peasant living in the village. But s...   \n",
       "\n",
       "              topic_modeling_1       topic_modeling_2  \\\n",
       "0            Future Prediction      Future Prediction   \n",
       "1     Role-playing, Evaluation  Role-play, Evaluation   \n",
       "2           Chatbot Evaluation     Chatbot Evaluation   \n",
       "3                Guessing Game          Word Guessing   \n",
       "4  Problem-Solving, Creativity        Problem Solving   \n",
       "\n",
       "               topic_modeling_3  \n",
       "0             Future Prediction  \n",
       "1  Creativity, Factual Accuracy  \n",
       "2            Chatbot Evaluation  \n",
       "3                 Word Guessing  \n",
       "4   Problem-solving, Creativity  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_and_hardness.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3200, 5)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_and_hardness.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3200, 256)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prompt_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prompt_length\n",
       "0             43"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform some data manipulation\n",
    "test_df = pd.DataFrame()\n",
    "test_df[\"prompt_length\"] = topic_and_hardness[\"prompt\"].apply(len)\n",
    "test_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_247</th>\n",
       "      <th>feature_248</th>\n",
       "      <th>feature_249</th>\n",
       "      <th>feature_250</th>\n",
       "      <th>feature_251</th>\n",
       "      <th>feature_252</th>\n",
       "      <th>feature_253</th>\n",
       "      <th>feature_254</th>\n",
       "      <th>feature_255</th>\n",
       "      <th>feature_256</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.055131</td>\n",
       "      <td>-0.115709</td>\n",
       "      <td>0.055225</td>\n",
       "      <td>0.050576</td>\n",
       "      <td>0.010953</td>\n",
       "      <td>-0.004206</td>\n",
       "      <td>0.062269</td>\n",
       "      <td>0.064194</td>\n",
       "      <td>0.06936</td>\n",
       "      <td>0.016847</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035079</td>\n",
       "      <td>-0.044518</td>\n",
       "      <td>0.043931</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>-0.076169</td>\n",
       "      <td>0.002721</td>\n",
       "      <td>0.008611</td>\n",
       "      <td>-0.01545</td>\n",
       "      <td>-0.033905</td>\n",
       "      <td>-0.057479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 256 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
       "0  -0.055131  -0.115709   0.055225   0.050576   0.010953  -0.004206   \n",
       "\n",
       "   feature_7  feature_8  feature_9  feature_10  ...  feature_247  feature_248  \\\n",
       "0   0.062269   0.064194    0.06936    0.016847  ...     0.035079    -0.044518   \n",
       "\n",
       "   feature_249  feature_250  feature_251  feature_252  feature_253  \\\n",
       "0     0.043931     0.000368    -0.076169     0.002721     0.008611   \n",
       "\n",
       "   feature_254  feature_255  feature_256  \n",
       "0     -0.01545    -0.033905    -0.057479  \n",
       "\n",
       "[1 rows x 256 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn the prompt embeddings data into a pandas dataframe\n",
    "num_features = test_prompt_embeddings.shape[1]\n",
    "column_names = [f\"feature_{i+1}\" for i in range(num_features)]\n",
    "embeddings = pd.DataFrame(test_prompt_embeddings, columns = column_names)\n",
    "embeddings.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_248</th>\n",
       "      <th>feature_249</th>\n",
       "      <th>feature_250</th>\n",
       "      <th>feature_251</th>\n",
       "      <th>feature_252</th>\n",
       "      <th>feature_253</th>\n",
       "      <th>feature_254</th>\n",
       "      <th>feature_255</th>\n",
       "      <th>feature_256</th>\n",
       "      <th>prompt_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.055131</td>\n",
       "      <td>-0.115709</td>\n",
       "      <td>0.055225</td>\n",
       "      <td>0.050576</td>\n",
       "      <td>0.010953</td>\n",
       "      <td>-0.004206</td>\n",
       "      <td>0.062269</td>\n",
       "      <td>0.064194</td>\n",
       "      <td>0.069360</td>\n",
       "      <td>0.016847</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.044518</td>\n",
       "      <td>0.043931</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>-0.076169</td>\n",
       "      <td>0.002721</td>\n",
       "      <td>0.008611</td>\n",
       "      <td>-0.015450</td>\n",
       "      <td>-0.033905</td>\n",
       "      <td>-0.057479</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.022181</td>\n",
       "      <td>-0.034712</td>\n",
       "      <td>-0.053046</td>\n",
       "      <td>-0.064429</td>\n",
       "      <td>-0.000790</td>\n",
       "      <td>-0.065599</td>\n",
       "      <td>-0.029762</td>\n",
       "      <td>0.032057</td>\n",
       "      <td>-0.108342</td>\n",
       "      <td>0.009685</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004786</td>\n",
       "      <td>0.011192</td>\n",
       "      <td>0.076667</td>\n",
       "      <td>0.121300</td>\n",
       "      <td>0.071898</td>\n",
       "      <td>0.045037</td>\n",
       "      <td>0.011844</td>\n",
       "      <td>-0.056735</td>\n",
       "      <td>0.109602</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.045638</td>\n",
       "      <td>-0.085029</td>\n",
       "      <td>0.004327</td>\n",
       "      <td>-0.047471</td>\n",
       "      <td>-0.024484</td>\n",
       "      <td>-0.026820</td>\n",
       "      <td>-0.066908</td>\n",
       "      <td>-0.002554</td>\n",
       "      <td>0.008854</td>\n",
       "      <td>0.065876</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.115438</td>\n",
       "      <td>0.019166</td>\n",
       "      <td>0.001164</td>\n",
       "      <td>0.026768</td>\n",
       "      <td>0.085855</td>\n",
       "      <td>-0.040475</td>\n",
       "      <td>-0.067115</td>\n",
       "      <td>0.079763</td>\n",
       "      <td>-0.029995</td>\n",
       "      <td>325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.007901</td>\n",
       "      <td>-0.037956</td>\n",
       "      <td>-0.083973</td>\n",
       "      <td>-0.018601</td>\n",
       "      <td>-0.066053</td>\n",
       "      <td>-0.065125</td>\n",
       "      <td>-0.009083</td>\n",
       "      <td>0.082465</td>\n",
       "      <td>-0.024516</td>\n",
       "      <td>-0.046597</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002550</td>\n",
       "      <td>0.045959</td>\n",
       "      <td>0.003057</td>\n",
       "      <td>0.098007</td>\n",
       "      <td>-0.028590</td>\n",
       "      <td>0.040015</td>\n",
       "      <td>-0.062342</td>\n",
       "      <td>-0.048916</td>\n",
       "      <td>-0.007213</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.051753</td>\n",
       "      <td>0.016543</td>\n",
       "      <td>0.055762</td>\n",
       "      <td>0.017472</td>\n",
       "      <td>-0.106851</td>\n",
       "      <td>-0.083537</td>\n",
       "      <td>0.059957</td>\n",
       "      <td>0.027934</td>\n",
       "      <td>-0.015560</td>\n",
       "      <td>0.034891</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059957</td>\n",
       "      <td>-0.005297</td>\n",
       "      <td>0.061444</td>\n",
       "      <td>-0.047929</td>\n",
       "      <td>0.111843</td>\n",
       "      <td>0.109400</td>\n",
       "      <td>0.096973</td>\n",
       "      <td>-0.042990</td>\n",
       "      <td>-0.052841</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 257 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
       "0  -0.055131  -0.115709   0.055225   0.050576   0.010953  -0.004206   \n",
       "1  -0.022181  -0.034712  -0.053046  -0.064429  -0.000790  -0.065599   \n",
       "2   0.045638  -0.085029   0.004327  -0.047471  -0.024484  -0.026820   \n",
       "3   0.007901  -0.037956  -0.083973  -0.018601  -0.066053  -0.065125   \n",
       "4   0.051753   0.016543   0.055762   0.017472  -0.106851  -0.083537   \n",
       "\n",
       "   feature_7  feature_8  feature_9  feature_10  ...  feature_248  feature_249  \\\n",
       "0   0.062269   0.064194   0.069360    0.016847  ...    -0.044518     0.043931   \n",
       "1  -0.029762   0.032057  -0.108342    0.009685  ...    -0.004786     0.011192   \n",
       "2  -0.066908  -0.002554   0.008854    0.065876  ...    -0.115438     0.019166   \n",
       "3  -0.009083   0.082465  -0.024516   -0.046597  ...    -0.002550     0.045959   \n",
       "4   0.059957   0.027934  -0.015560    0.034891  ...    -0.059957    -0.005297   \n",
       "\n",
       "   feature_250  feature_251  feature_252  feature_253  feature_254  \\\n",
       "0     0.000368    -0.076169     0.002721     0.008611    -0.015450   \n",
       "1     0.076667     0.121300     0.071898     0.045037     0.011844   \n",
       "2     0.001164     0.026768     0.085855    -0.040475    -0.067115   \n",
       "3     0.003057     0.098007    -0.028590     0.040015    -0.062342   \n",
       "4     0.061444    -0.047929     0.111843     0.109400     0.096973   \n",
       "\n",
       "   feature_255  feature_256  prompt_length  \n",
       "0    -0.033905    -0.057479             43  \n",
       "1    -0.056735     0.109602             34  \n",
       "2     0.079763    -0.029995            325  \n",
       "3    -0.048916    -0.007213             37  \n",
       "4    -0.042990    -0.052841            166  \n",
       "\n",
       "[5 rows x 257 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the modelling data\n",
    "test_data = pd.concat([embeddings, test_df], axis = 1)\n",
    "test_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data.\n",
    "scaler = StandardScaler()\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_test_s = scaler.transform(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msse-python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
